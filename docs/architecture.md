# DeFiLlama Server - System Architecture

*Generated by BMAD Method v6.0.0-alpha.0 on 2025-10-13*

## üèóÔ∏è High-Level Architecture

DeFiLlama Server implements a **serverless microservices architecture** on AWS, designed for high scalability, cost efficiency, and global availability. The system processes billions of data points daily from 100+ blockchains to provide real-time DeFi analytics.

```mermaid
graph TB
    subgraph "External Data Sources"
        BC[Blockchain RPCs]
        CG[CoinGecko API]
        SG[Subgraphs]
        PA[Protocol APIs]
    end
    
    subgraph "AWS Infrastructure"
        subgraph "DeFi Service"
            DF_API[DeFi Lambda Functions]
            DF_DB[(DynamoDB)]
            DF_PG[(PostgreSQL)]
        end
        
        subgraph "Coins Service"
            CN_API[Coins Lambda Functions]
            CN_DB[(DynamoDB)]
            CN_PG[(PostgreSQL)]
            CN_RD[(Redis Cache)]
            CN_KF[Kafka Queue]
        end
        
        subgraph "Shared Infrastructure"
            S3[S3 Storage]
            CF[CloudFront CDN]
            ES[Elasticsearch]
        end
    end
    
    subgraph "Client Applications"
        WEB[DeFiLlama Website]
        API_USERS[API Consumers]
        MOBILE[Mobile Apps]
    end
    
    BC --> DF_API
    CG --> CN_API
    SG --> DF_API
    PA --> DF_API
    
    DF_API --> DF_DB
    DF_API --> DF_PG
    DF_API --> S3
    DF_API --> ES
    
    CN_API --> CN_DB
    CN_API --> CN_PG
    CN_API --> CN_RD
    CN_API --> CN_KF
    CN_API --> S3
    
    CF --> DF_API
    CF --> CN_API
    
    WEB --> CF
    API_USERS --> CF
    MOBILE --> CF
```

## üéØ Service Architecture

### DeFi Service Architecture

**Purpose**: Core DeFi analytics and TVL tracking service

```mermaid
graph LR
    subgraph "DeFi Service (defi/)"
        subgraph "API Layer"
            API[REST API Endpoints]
            WS[WebSocket Handlers]
        end
        
        subgraph "Business Logic"
            TVL[TVL Calculator]
            PROTO[Protocol Manager]
            HIST[Historical Data]
            GOV[Governance Data]
            EMIT[Emissions Tracker]
        end
        
        subgraph "Data Layer"
            ADP[Adapter Engine]
            CACHE[Caching Layer]
            VALID[Data Validation]
        end
        
        subgraph "External Adapters"
            DLA[DefiLlama-Adapters]
            DIM[Dimension-Adapters]
            EMI[Emissions-Adapters]
        end
    end
    
    API --> TVL
    API --> PROTO
    API --> HIST
    WS --> TVL
    
    TVL --> ADP
    PROTO --> ADP
    HIST --> CACHE
    GOV --> CACHE
    EMIT --> ADP
    
    ADP --> DLA
    ADP --> DIM
    ADP --> EMI
```

### Coins Service Architecture

**Purpose**: Multi-chain cryptocurrency price aggregation and distribution

```mermaid
graph LR
    subgraph "Coins Service (coins/)"
        subgraph "API Layer"
            PRICE_API[Price API]
            HIST_API[Historical API]
        end
        
        subgraph "Data Processing"
            AGG[Price Aggregator]
            NORM[Price Normalizer]
            BRIDGE[Bridge Handler]
        end
        
        subgraph "Data Sources"
            CG_INT[CoinGecko Integration]
            CHAIN[Chain Scanners]
            DEX[DEX Price Feeds]
        end
        
        subgraph "Storage & Cache"
            REDIS[Redis Cache]
            KAFKA[Kafka Queue]
            PG[PostgreSQL]
        end
    end
    
    PRICE_API --> AGG
    HIST_API --> AGG
    
    AGG --> NORM
    NORM --> BRIDGE
    
    CG_INT --> AGG
    CHAIN --> AGG
    DEX --> AGG
    
    AGG --> REDIS
    AGG --> KAFKA
    NORM --> PG
```

## üóÑÔ∏è Data Architecture

### Database Design

**DynamoDB (NoSQL)**
- **Purpose**: High-throughput operational data
- **Tables**: 
  - `prod-table` (DeFi service)
  - `prod-coins-table` (Coins service)
- **Access Patterns**: Time-series queries, protocol lookups
- **Partitioning**: By protocol ID and timestamp

**PostgreSQL (Relational)**
- **Purpose**: Complex queries and analytics
- **Schema**: Normalized protocol and price data
- **Features**: Full-text search, complex joins, historical analysis
- **Backup**: Automated daily snapshots

**Redis (Cache)**
- **Purpose**: High-frequency price data caching
- **TTL**: 30 seconds to 5 minutes depending on data type
- **Patterns**: Price lookups, rate limiting, session storage

### Data Flow Architecture

```mermaid
sequenceDiagram
    participant Client
    participant CloudFront
    participant Lambda
    participant Cache
    participant Database
    participant Blockchain
    
    Client->>CloudFront: API Request
    CloudFront->>Lambda: Forward Request
    Lambda->>Cache: Check Cache
    
    alt Cache Hit
        Cache-->>Lambda: Return Cached Data
    else Cache Miss
        Lambda->>Database: Query Database
        Database-->>Lambda: Return Data
        Lambda->>Cache: Update Cache
    end
    
    Lambda-->>CloudFront: Response
    CloudFront-->>Client: Cached Response
    
    Note over Lambda,Blockchain: Background Data Updates
    Lambda->>Blockchain: Fetch Latest Data
    Blockchain-->>Lambda: Blockchain Data
    Lambda->>Database: Update Database
    Lambda->>Cache: Invalidate Cache
```

## ‚ö° Performance Architecture

### Caching Strategy

**Multi-Layer Caching**:
1. **CloudFront (CDN)**: 5-60 minutes for static data
2. **Redis**: 30 seconds - 5 minutes for dynamic data  
3. **Application Cache**: In-memory caching for computed values
4. **Database Query Cache**: PostgreSQL query result caching

### Scaling Patterns

**Horizontal Scaling**:
- Lambda auto-scaling based on request volume
- DynamoDB on-demand scaling
- Redis cluster mode for high availability

**Vertical Optimization**:
- Memory optimization for Lambda functions (250MB - 10GB)
- Database connection pooling
- Batch processing for bulk operations

## üîí Security Architecture

### Authentication & Authorization
- **API Keys**: Rate-limited public API access
- **AWS IAM**: Service-to-service authentication
- **VPC**: Network isolation for databases
- **Encryption**: TLS 1.3 for data in transit, AES-256 for data at rest

### Data Protection
- **Input Validation**: Comprehensive request validation
- **Rate Limiting**: Per-IP and per-API-key limits
- **DDoS Protection**: CloudFront + AWS Shield
- **Monitoring**: AWS X-Ray + CloudWatch for anomaly detection

## üåç Deployment Architecture

### Infrastructure as Code
```yaml
# Serverless Framework Configuration
service: defillama
provider:
  name: aws
  runtime: nodejs20.x
  region: eu-central-1
  stage: ${opt:stage, 'dev'}
  
functions:
  api:
    handler: src/handler.api
    events:
      - http:
          path: /{proxy+}
          method: ANY
    environment:
      tableName: ${self:custom.tableName}
```

### CI/CD Pipeline
1. **Code Commit**: GitHub repository
2. **Build**: Serverless Framework packaging
3. **Test**: Jest unit and integration tests
4. **Deploy**: Automated deployment to dev/prod
5. **Monitor**: CloudWatch metrics and alarms

### Environment Management
- **Development**: `dev` stage with reduced resources
- **Production**: `prod` stage with full scaling
- **Configuration**: Environment-specific variables
- **Secrets**: AWS Secrets Manager integration

## üìä Monitoring & Observability

### Metrics & Logging
- **Application Metrics**: Custom CloudWatch metrics
- **Performance Monitoring**: AWS X-Ray distributed tracing
- **Error Tracking**: Sentry integration (coins service)
- **Log Aggregation**: CloudWatch Logs with structured logging

### Health Checks
- **API Health**: Automated endpoint monitoring
- **Database Health**: Connection and query performance
- **Cache Health**: Redis cluster monitoring
- **External Dependencies**: Blockchain RPC monitoring

## üîÑ Data Synchronization

### Real-time Updates
- **WebSocket Connections**: Live price feeds
- **Event-Driven Architecture**: Kafka message queues
- **Background Jobs**: Scheduled Lambda functions
- **Change Data Capture**: Database triggers for cache invalidation

### Batch Processing
- **Historical Data**: Daily batch jobs for historical analysis
- **Data Validation**: Periodic data integrity checks
- **Backup & Archive**: Automated data archival to S3

---

*This architecture documentation was generated using BMAD Method v6.0.0-alpha.0 system analysis.*
